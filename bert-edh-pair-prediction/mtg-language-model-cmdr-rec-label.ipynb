{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mtg language model: commander to recommendation task\n",
    "\n",
    "this is functionally the same as the neighboring notebook except this is pre-trained not on the \"card to card\" nsp task but a \"commander: card\" nsp task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import functools\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tokenizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import (BertConfig,\n",
    "                          BertForPreTraining,\n",
    "                          BertForNextSentencePrediction,\n",
    "                          BertTokenizerFast,\n",
    "                          DataCollatorForLanguageModeling,\n",
    "                          EarlyStoppingCallback,\n",
    "                          Trainer,\n",
    "                          TrainingArguments,\n",
    "                          pipeline, )\n",
    "\n",
    "from utils import build_tokenizer_map_func, grouper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_LOCAL_LAPTOP = False\n",
    "TRAIN_TOKENIZER = False\n",
    "MAKE_MLM_NSP_DATASET_INPUTS = False\n",
    "MAKE_MLM_NSP_DATASET = False\n",
    "DO_CHUNKED_DATASET_BUILDING = False\n",
    "SAVE_DATASET_TO_FILE = False\n",
    "LOAD_DATASET_FROM_FILE = False\n",
    "DO_PRE_TRAINING = False\n",
    "DO_SMALL_PRETRAIN_TEST = False\n",
    "CHECK_PRETRAINED_MODEL_RESULTS = False\n",
    "MAKE_DECK_RECOMMENDATION_INPUTS = False\n",
    "DO_DECK_RECOMMENDATIONS = False\n",
    "\n",
    "# whether or not we cap the number of card pairs, or we choose or use\n",
    "# all possible pairs\n",
    "NUM_MAX_PAIRS = None\n",
    "# NUM_MAX_PAIRS = 500\n",
    "# NUM_MAX_PAIRS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_TOKENIZER:\n",
    "    assert IS_LOCAL_LAPTOP\n",
    "    \n",
    "if DO_CHUNKED_DATASET_BUILDING:\n",
    "    assert NUM_MAX_PAIRS is not None, \"this is like 2 TB of data\"\n",
    "\n",
    "if MAKE_MLM_NSP_DATASET_INPUTS:\n",
    "    assert IS_LOCAL_LAPTOP\n",
    "\n",
    "if MAKE_DECK_RECOMMENDATION_INPUTS:\n",
    "    assert IS_LOCAL_LAPTOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS = ['train', 'validation', 'test_cmdr', 'test_set']\n",
    "SEED = 1337\n",
    "\n",
    "# for the chunking of the dataset builder\n",
    "\n",
    "N_PROCS = os.cpu_count()\n",
    "N_CHUNKS = N_PROCS * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get raw text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_LOCAL_LAPTOP:\n",
    "    import mtg.cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(None)\n",
    "def get_cards():\n",
    "    cards = (mtg.cards.cards_df()\n",
    "             [['name', 'multiverseId', 'scryfallId', 'type', 'manaCost',\n",
    "               'text', 'setname', 'power', 'toughness']]\n",
    "             .sort_values(by=['name', 'multiverseId'], ascending=False)\n",
    "             .groupby('name')\n",
    "             .first())\n",
    "    cards.index = cards.index.str.lower()\n",
    "    cards = cards[cards.type != 'Scheme']\n",
    "    cards.loc[:, 'mytext'] = (cards.manaCost.fillna('{0}')\n",
    "                              + ' '\n",
    "                              + cards.type\n",
    "                              + ((' ' + cards.power + '/' + cards.toughness).fillna(''))\n",
    "                              + ': '\n",
    "                              + cards.text.str.replace('\\s+', ' ').fillna(''))\n",
    "    cards.mytext = cards.mytext.str.lower().str.replace('[\"\\']', '')\n",
    "    return cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_CORPUS = 'mtg-corpus.txt'\n",
    "\n",
    "def get_corpus(f=F_CORPUS):\n",
    "    get_cards().mytext.to_csv(f, header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_TOKENIZER:\n",
    "    get_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_TOKENIZER:\n",
    "    !head -n5 mtg-corpus.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train a tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found the `BERT` special tokens by looking at the defaults for\n",
    "\n",
    "```py\n",
    "tokenizers.BertWordPieceTokenizer.train?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "MODEL_NAME = 'mtg-language-v2'\n",
    "\n",
    "# if you run with vocab_size = 300_000 (default), you get 11,761 vocab items\n",
    "# any number larger than that will include null tokens and will also include\n",
    "# single words. we will choose a number that is *just* below that here\n",
    "VOCAB_SIZE = 11_500\n",
    "\n",
    "if TRAIN_TOKENIZER:\n",
    "    #trainable_tokenizer = tokenizers.ByteLevelBPETokenizer(lowercase=True)\n",
    "    trainable_tokenizer = tokenizers.BertWordPieceTokenizer(lowercase=True)\n",
    "    \n",
    "    trainable_tokenizer.train(files=F_CORPUS,\n",
    "                              vocab_size=VOCAB_SIZE,\n",
    "                              special_tokens=['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]'])\n",
    "    \n",
    "    !mkdir -p {MODEL_NAME}\n",
    "\n",
    "    trainable_tokenizer.save_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if TRAIN_TOKENIZER:\n",
    "    !tail -n40 {MODEL_NAME}/vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_TOKENIZER:\n",
    "    !wc -l {MODEL_NAME}/vocab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make a training dataset\n",
    "\n",
    "we will do pre-training of a completely un-initialized model down below, so we will need a dataset to train on to do that. `bert` has two objectives -- a masked language model (mlm) and a next sentence prediction.\n",
    "\n",
    "in order to do this, we will need to create a dataset with the following features:\n",
    "\n",
    "+ standard bert tokenizer outputs\n",
    "    + `input_ids`\n",
    "    + `attentention_mask`\n",
    "    + `token_type_ids`\n",
    "+ `labels`: _optional_, these are basically the same thing as `input_ids`, but allow for ignoring certain tokens for the purpose of loss calculations\n",
    "+ `next_sentence_label`: these are the `0, 1` values indicating whether or not sentences A and B are continuations (in the original model) or `edhrec` commander / card pairs (our model)\n",
    "\n",
    "more is better here, of course; I think the goal has to be full coverage of all cards and all edhrec pair-ups. to that end, I will create a dataset builder of a generator type.\n",
    "\n",
    "+ [writing a dataset loading script walkthrough here](https://huggingface.co/docs/datasets/add_dataset.html)\n",
    "+ [code template example here](https://github.com/huggingface/datasets/blob/master/templates/new_dataset_script.py)\n",
    "\n",
    "we have a few steps:\n",
    "\n",
    "1. create a train / test / val split of card names\n",
    "1. create a train / test / val split of edhrec pairings\n",
    "1. save the above to files we can move around (parquet is fine)\n",
    "1. create a datasetloader object that can take the above and generate the full datasets (and I do mean full!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train / test / val split\n",
    "\n",
    "there are two types of generalization we care about:\n",
    "\n",
    "+ how does it generalize to a completely new commander?\n",
    "+ how does it generalize to a completely new set of recommendation cards?\n",
    "\n",
    "we will create a pair of test sets instead of just one:\n",
    "\n",
    "1. all recommendations from a number of held-out commanders\n",
    "1. all recommendations for 2 held out mtg sets (`ZNR` and `IKO` are the most recent sets with json data as of 2020-01-17, so we will use those)\n",
    "\n",
    "for train and validation, we will split based on set, as we did previously. this will give us a train and val set of cards, and we will apply that split to *both* commanders and recommended cards.\n",
    "\n",
    "a given record is a pair of commander and card, so if all things are equal, we have four types of pairs. assuming our test holdout is equally likely to be a commander or a recommended card, and a holdout fraction of `alpha` would result in\n",
    "\n",
    "| commander | card | frac |\n",
    "|-|-|-|\n",
    "| control | control | `(1 - alpha) ** 2` |\n",
    "| test | control | `(1 - alpha) * alpha` |\n",
    "| control | test | `(1 - alpha) * alpha` |\n",
    "| test | test | `alpha ** 2` |\n",
    "\n",
    "of these, only the first is in our train dataset. if we want the train dataset here to be 95% of all records, we need `(1 - alpha) ** 2 = 0.95`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1 - 0.95 ** .5\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'mtg-language-cmdr-rec-data'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_MLM_NSP_DATASET_INPUTS:\n",
    "    import mtg.extract.edhrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_commanders(target_test_frac, commanders=None, seed=SEED):\n",
    "    if commanders is None:\n",
    "        commanders = (mtg.extract.edhrec.get_commanders_and_cards()\n",
    "                      .commander\n",
    "                      .unique())\n",
    "    np.random.seed(seed)\n",
    "    return np.random.choice(commanders,\n",
    "                            size=round(commanders.size * target_test_frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_card_name(c):\n",
    "    return c.lower().split(' // ')[0]\n",
    "\n",
    "assert clean_card_name('Bruna, the Fading Light // Brisela, Voice of Nightmares') == 'bruna, the fading light'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SETNAMES = ['ZNR']\n",
    "TEST_CMDR_FRAC = 0.03\n",
    "VAL_FRAC = alpha\n",
    "\n",
    "\n",
    "if MAKE_MLM_NSP_DATASET_INPUTS:\n",
    "    edhrec_cards = (mtg.extract.edhrec.get_commanders_and_cards()\n",
    "                    [['name', 'commander']])\n",
    "    edhrec_cards.name = edhrec_cards.name.apply(clean_card_name)\n",
    "    edhrec_cards.commander = edhrec_cards.commander.apply(clean_card_name)\n",
    "    edhrec_cards.name = edhrec_cards.name.str.lower().str.replace('//', '/')\n",
    "    edhrec_cards.commander = edhrec_cards.commander.str.lower().str.replace('//', '/')\n",
    "    commanders = edhrec_cards.commander.unique()\n",
    "    \n",
    "    # make the two test sets\n",
    "    \n",
    "    # test commanders\n",
    "    test_commanders = get_test_commanders(TEST_CMDR_FRAC, commanders)\n",
    "    is_test_commander = edhrec_cards.commander.isin(test_commanders)\n",
    "    test_cmdr = edhrec_cards[is_test_commander]\n",
    "    \n",
    "    # test set cards\n",
    "    cards = get_cards()\n",
    "    cardsets = (cards\n",
    "                .reset_index()\n",
    "                [['name', 'setname']])\n",
    "    edhrec_cards = (edhrec_cards\n",
    "                    # card set\n",
    "                    .merge(cardsets, how='left', on='name')\n",
    "                    .merge(cardsets.rename(columns={'setname': 'cmdr_setname',\n",
    "                                                    'name': 'commander'}),\n",
    "                           how='left', on='commander'))\n",
    "    is_test_set = ((~is_test_commander)\n",
    "                   & (edhrec_cards.setname.isin(TEST_SETNAMES)\n",
    "                      | edhrec_cards.cmdr_setname.isin(TEST_SETNAMES)))\n",
    "    test_set = edhrec_cards[is_test_set]\n",
    "\n",
    "    # make the train and val sets. split all cards based on alpha, then\n",
    "    # subset the non-test cards based on whether either side is in the val set\n",
    "    is_test = is_test_commander | is_test_set\n",
    "    train_val = edhrec_cards[~is_test]\n",
    "    \n",
    "    train_val_cards = cards[~cards.setname.isin(TEST_SETNAMES)].index.values\n",
    "    val_cards = np.random.choice(train_val_cards,\n",
    "                                 size=round(train_val_cards.size * VAL_FRAC))\n",
    "\n",
    "    has_val_card = (train_val.name.isin(val_cards)\n",
    "                    | train_val.commander.isin(val_cards))\n",
    "    \n",
    "    val = train_val[has_val_card]\n",
    "    train = train_val[~has_val_card]\n",
    "\n",
    "    print(f\"num records train:       {train.shape[0]:,} ({train.shape[0] / edhrec_cards.shape[0]:.2%})\")\n",
    "    print(f\"num records val:         {val.shape[0]:,} ({val.shape[0] / edhrec_cards.shape[0]:.2%})\")\n",
    "    print(f\"num records test (cmdr): {test_cmdr.shape[0]:,} ({test_cmdr.shape[0] / edhrec_cards.shape[0]:.2%})\")\n",
    "    print(f\"num records test (set):  {test_set.shape[0]:,} ({test_set.shape[0] / edhrec_cards.shape[0]:.2%})\")\n",
    "    \n",
    "    # save card splits (will be used for negative labels)\n",
    "    # this is a little tricky: we want train to just be train,\n",
    "    # but all the others can be any card (val, test_cmdr, test_set)\n",
    "    train_cards = (cards\n",
    "                   [(~cards.setname.isin(TEST_SETNAMES))\n",
    "                    & (~cards.index.isin(val_cards))])\n",
    "    \n",
    "    train_cards.to_parquet(os.path.join(DATA_DIR, 'cards.train.parquet'), index=True)\n",
    "    for splitname in ['validation', 'test_cmdr', 'test_set']:\n",
    "        cards.to_parquet(os.path.join(DATA_DIR, f'cards.{splitname}.parquet'), index=True)\n",
    "    \n",
    "    # save edhrecs\n",
    "    train.to_parquet(os.path.join(DATA_DIR, \"edhrec.train.parquet\"), index=False)\n",
    "    val.to_parquet(os.path.join(DATA_DIR, \"edhrec.validation.parquet\"), index=False)\n",
    "    test_cmdr.to_parquet(os.path.join(DATA_DIR, \"edhrec.test_cmdr.parquet\"), index=False)\n",
    "    test_set.to_parquet(os.path.join(DATA_DIR, \"edhrec.test_set.parquet\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the datasetbuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -alh {DATA_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # quick check on the max length of our sequences:\n",
    "# # we can easily build a tokenizer and apply it to every sentence\n",
    "# # directly; this will give us a max length for a single sentence\n",
    "# # and then our dataset max length is approx double that.\n",
    "\n",
    "# from transformers import BertTokenizerFast\n",
    "\n",
    "# tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# z = tokenizer(cards.mytext.unique().tolist(), max_length=1024)\n",
    "\n",
    "# import collections\n",
    "\n",
    "# l = [len(_) for _ in z['input_ids']]\n",
    "# c = collections.Counter(l)\n",
    "\n",
    "# df = (pd.DataFrame([{'k': k, 'v': v} for (k, v) in c.items()])\n",
    "#       .sort_values(by='k'))\n",
    "# df.loc[:, 'cs'] = df.v.cumsum() / df.v.sum()\n",
    "# print(f\"max single sequence length: {df.k.max()}\")\n",
    "# # df.plot('k', 'cs')\n",
    "\n",
    "# import numpy as np\n",
    "# pairs = np.random.choice(l, size=(100_000, 2))\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(pairs.sum(axis=1), bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "moral of the story from the above: almost every card is <100 tokens, max is 185. almost every *pair* of sequences is under 175 total tokens. 200 is *extremely* conservative actually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunked_dataset_shell_cmd(n_chunks, c, num_max_pairs, max_seq_length):\n",
    "    nmp_flag = f' -m {num_max_pairs}' if num_max_pairs is not None else ''\n",
    "    return (f'python edhrec_dataset_chunk_proc.py'\n",
    "            f' -n {N_CHUNKS}'\n",
    "            f' -c {c}'\n",
    "            f' -d mtg-language-data-cmdr-rec-data'\n",
    "            f' -o mtg-mlm-nsp-cmdr-rec-dataset-chunks'\n",
    "            f'{nmp_flag}'\n",
    "            f' -l {max_seq_length}'\n",
    "            f' -p cmdr-rec'\n",
    "            f' > logs/log.{c}.txt 2>&1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the logs and outputs\n",
    "if DO_CHUNKED_DATASET_BUILDING:\n",
    "    shutil.rmtree('logs', ignore_errors=True)\n",
    "    shutil.rmtree('mtg-mlm-nsp-cmdr-rec-dataset-chunks/', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 200\n",
    "\n",
    "if MAKE_MLM_NSP_DATASET:\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "    \n",
    "    for split in SPLITS:\n",
    "        n = pd.read_parquet(os.path.join(DATA_DIR, f'cards.{split}.parquet')).shape[0]\n",
    "        print(f\"num records {split}: {n}\")\n",
    "    \n",
    "    if DO_CHUNKED_DATASET_BUILDING:\n",
    "        if not os.path.isdir('logs'):\n",
    "            os.makedirs('logs')\n",
    "\n",
    "        commands = [make_chunked_dataset_shell_cmd(N_CHUNKS, c, NUM_MAX_PAIRS, MAX_SEQ_LENGTH)\n",
    "                    for c in range(N_CHUNKS)]\n",
    "\n",
    "        print(f'executing {N_CHUNKS} commands in chunks of {N_PROCS} parallel commands')\n",
    "\n",
    "        for cmd_grp in grouper(tqdm(commands), N_PROCS, ''):\n",
    "            processes = [subprocess.Popen(cmd, shell=True) for cmd in cmd_grp]\n",
    "            for p in processes:\n",
    "                p.wait()\n",
    "\n",
    "            # we just saved 5 chunks in two places -- the hf cache directory\n",
    "            # and the local directory. to avoid running out of disk space, we\n",
    "            # will wipe the cache directory after every proc group\n",
    "            hf_cache_dir = os.path.join(os.path.expanduser('~'), '.cache', 'huggingface', 'datasets')\n",
    "            if os.path.isdir(hf_cache_dir):\n",
    "                shutil.rmtree(hf_cache_dir)\n",
    "\n",
    "        base_dataset = datasets.DatasetDict({\n",
    "            split: datasets.concatenate_datasets(\n",
    "                [datasets.load_from_disk(f)[split]\n",
    "                 for f in glob.glob('mtg-mlm-nsp-cmdr-rec-dataset-chunks/*')])\n",
    "            for split in SPLITS})\n",
    "    else:\n",
    "        tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "        tokenizer_map_func = build_tokenizer_map_func(tokenizer, max_length=MAX_SEQ_LENGTH)\n",
    "        \n",
    "        base_dataset = (datasets.load_dataset('edhrec_dataset.py',\n",
    "                                              data_dir=DATA_DIR,\n",
    "                                              num_max_pairs=NUM_MAX_PAIRS,\n",
    "                                              pair_type='cmdr-rec')\n",
    "                        .map(tokenizer_map_func, batched=False, num_proc=N_PROCS))\n",
    "\n",
    "    dataset = (base_dataset\n",
    "               .shuffle(seeds={split: SEED for split in SPLITS}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset if MAKE_MLM_NSP_DATASET else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset.shape if MAKE_MLM_NSP_DATASET else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset if MAKE_MLM_NSP_DATASET else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.shape if MAKE_MLM_NSP_DATASET else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_DATASET_TO_FILE:\n",
    "    dataset.save_to_disk('mtg-mlm-nsp-cmdr-rec-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%sh\n",
    "# aws s3 ls s3://mtg-research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_DATASET_FROM_FILE:\n",
    "    f = 'mtg-mlm-nsp-cmdr-rec-dataset-small' if DO_SMALL_PRETRAIN_TEST else 'mtg-mlm-nsp-cmdr-rec-dataset'\n",
    "    dataset = datasets.load_from_disk(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset if LOAD_DATASET_FROM_FILE else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check the next sentence labels!\n",
    "import pandas as pd\n",
    "\n",
    "if LOAD_DATASET_FROM_FILE:\n",
    "    z = dataset['train'][:10]\n",
    "\n",
    "(pd.DataFrame({k: z[k]\n",
    "               for k in ['name_a', 'name_b', 'next_sentence_label', 'rec_set_type']})\n",
    " if LOAD_DATASET_FROM_FILE\n",
    " else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the smaller dataset defined above,\n",
    "\n",
    "+ ~~add the tokenizer~~\n",
    "+ ~~build the trainer and train config~~\n",
    "+ ~~do a train round with the smaller datasets~~\n",
    "+ ~~any difference at all??~~\n",
    "\n",
    "if it looks promising,\n",
    "\n",
    "+ build a *real* dataset\n",
    "    + ~~write chunked dataset processer to leverage multiple cpus~~\n",
    "    + ~~move to a **CPU** box -- not a GPU box. this dataset creation is done on the CPU.~~\n",
    "    + ~~set up cpu box~~\n",
    "        + `ssh-keygen -t ed25519 -C \"r.zach.lamberty@gmail.com\"`\n",
    "        + `cat ~/.ssh/id_ed25519.pub`\n",
    "        + add to github [here](https://github.com/settings/keys)\n",
    "        + `git clone git@github.com:RZachLamberty/mtg-research.git`\n",
    "        + `source activate ...`\n",
    "        + `pip install datasets transformers`\n",
    "        + `jupyter notebook --no-browser --ip=0.0.0.0`\n",
    "    + ~~locally~~\n",
    "        + `ssh -NfL 9999:localhost:8888 rzlcpu`\n",
    "        + https://localhost:9999\n",
    "        + `scp -r mtg-language rzlcpu:~/mtg-research/bert-edh-pair-prediction/mtg-language`\n",
    "        + `scp -r mtg-language-data rzlcpu:~/mtg-research/bert-edh-pair-prediction/mtg-language-data`\n",
    "    + ~~in the jupyter notebook, update the flags at the top~~\n",
    "        + `True`:\n",
    "            + `MAKE_MLM_NSP_DATASET`\n",
    "            + `DO_CHUNKED_DATASET_BUILDING`\n",
    "            + `SAVE_DATASET_TO_FILE`\n",
    "        + all others `False`\n",
    "    + ~~save this dataset and copy it down~~\n",
    "+ train\n",
    "    + move to GPU\n",
    "    + set up gpu box\n",
    "        + try a `p2.8xlarge` instead of the p3\n",
    "        + hard drive should be at least 500 gb\n",
    "        + attach the read s3 iam role\n",
    "        + `ssh-keygen -t ed25519 -C \"r.zach.lamberty@gmail.com\"`\n",
    "        + `cat ~/.ssh/id_ed25519.pub`\n",
    "        + add to github [here](https://github.com/settings/keys)\n",
    "        + `git clone git@github.com:RZachLamberty/mtg-research.git`\n",
    "        + in a new terminal, kick this off asap:\n",
    "            + `aws s3 sync s3://mtg-research/bert-edh-pair-prediction/mtg-mlm-nsp-dataset mtg-mlm-nsp-dataset`\n",
    "        + go back to the original terminal\n",
    "        + `screen -S j`\n",
    "        + `source activate ...`\n",
    "        + `pip install datasets transformers`\n",
    "        + `jupyter notebook --no-browser --ip=0.0.0.0`\n",
    "        + `cd ~/mtg-research/bert-edh-pair-prediction`\n",
    "    + run it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-training\n",
    "\n",
    "we actually do care most about the nsp (next sentence prediction) task -- for us, that's the \"is edhrec pair / isn't edhrec pair\" concept. this means we *have* to do a `bert` model, because all of the other models dropped that task in favor of others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE WERE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_PRE_TRAINING:\n",
    "    config = BertConfig(vocab_size=VOCAB_SIZE)\n",
    "\n",
    "    model = BertForPreTraining(config=config)\n",
    "    # # use this format to pick up from an aborted run\n",
    "    # model = BertForPreTraining.from_pretrained(f'./{output_dir}/checkpoint-5750')\n",
    "    \n",
    "    tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    print(f'number of params in model: {model.num_parameters():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_PRE_TRAINING:\n",
    "    if DO_SMALL_PRETRAIN_TEST:\n",
    "        TRAIN_BATCH = 8\n",
    "        EVAL_BATCH = 8\n",
    "        LOGGING_STEPS = 250\n",
    "        EARLY_STOPPING_PATIENCE = 8\n",
    "        train_dataset = dataset['train'].select(range(80))\n",
    "        eval_dataset = dataset['validation'].select(range(80))\n",
    "        output_dir = './mtg-language-results-v2-small'\n",
    "    else:\n",
    "        TRAIN_BATCH = 51\n",
    "        EVAL_BATCH = 186\n",
    "        #LOGGING_STEPS = 50\n",
    "        #EARLY_STOPPING_PATIENCE = 8\n",
    "        LOGGING_STEPS = 100\n",
    "        EARLY_STOPPING_PATIENCE = 5\n",
    "        train_dataset = dataset['train']\n",
    "        eval_dataset = dataset['validation']\n",
    "        \n",
    "        ## every 100th record, then cut down to an exact batch\n",
    "        ## size multiple, caculated as:\n",
    "        ##   # divmod(dataset['validation'].num_rows // 10, 186)[0] * 186\n",
    "        #eval_dataset = (dataset['validation']\n",
    "        #                .filter(lambda example, indice: indice % 10 == 0,\n",
    "        #                        with_indices=True)\n",
    "        #                .filter(lambda example, indice: indice < 2_232,\n",
    "        #                        with_indices=True))\n",
    "        #\n",
    "        #assert eval_dataset.num_rows % EVAL_BATCH == 0\n",
    "        #print(eval_dataset.num_rows)\n",
    "        output_dir = './mtg-language-results-v2'\n",
    "    \n",
    "    # this callback just says that if there are 8 consecutive (measured every\n",
    "    # eval_steps = ogging_steps steps) eval losses greater than the one at t0,\n",
    "    # kill the job\n",
    "    esc = EarlyStoppingCallback(early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "                                early_stopping_threshold=0.0)\n",
    "    \n",
    "    # this is responsible for adding the `labels`feature that we actually train on\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,\n",
    "                                                    mlm=True,\n",
    "                                                    mlm_probability=0.15)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,                    # output directory\n",
    "        num_train_epochs=1,                       # total # of training epochs\n",
    "        per_device_train_batch_size=TRAIN_BATCH,  # batch size per device during training\n",
    "        per_device_eval_batch_size=EVAL_BATCH,    # batch size for evaluation\n",
    "        warmup_steps=500,                         # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,                        # strength of weight decay\n",
    "        logging_dir='./logs',                     # directory for storing logs\n",
    "        # my custom ones\n",
    "        logging_steps=LOGGING_STEPS,\n",
    "        overwrite_output_dir=True,\n",
    "        evaluation_strategy='steps',\n",
    "        logging_first_step=True,\n",
    "        seed=1337,\n",
    "        dataloader_drop_last=True,\n",
    "        dataloader_num_workers=30,\n",
    "        #label_names=['labels', 'next_sentence_label'],\n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=10,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,                  # the instantiated 🤗 Transformers model to be trained\n",
    "        args=training_args,           # training arguments, defined above\n",
    "        train_dataset=train_dataset,  # training dataset\n",
    "        eval_dataset=eval_dataset,    # evaluation dataset\n",
    "        callbacks=[esc],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if DO_PRE_TRAINING:\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_dir = 'mtg-language-v2-test-small' if DO_SMALL_PRETRAIN_TEST else MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_PRE_TRAINING:\n",
    "    trainer.save_model(local_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_PRE_TRAINING:\n",
    "    evals = {split: trainer.evaluate(dataset[split])\n",
    "             for split in ['test_cmdr', 'test_set']\n",
    "             if split != 'train'}\n",
    "\n",
    "evals if DO_PRE_TRAINING else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mask = pipeline(\n",
    "    'fill-mask',\n",
    "    model=local_model_dir,\n",
    "    tokenizer=tokenizer) if DO_PRE_TRAINING else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is to get the text string we mask below\n",
    "# dataset['validation'][0]['text_a'] if DO_PRE_TRAINING else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy: legendary [MASK] -- vampire knight\n",
    "fill_mask('{3}{w}{b} legendary [MASK] — vampire knight 4/4: vigilance, lifelink {t}, pay 7 life: destroy target nonland permanent. activate this ability only during your turn.') if DO_PRE_TRAINING else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# harder: destroy target nonland [MASK] (permanent)\n",
    "fill_mask('{3}{w}{b} legendary creature — vampire knight 4/4: vigilance, lifelink {t}, pay 7 life: destroy target nonland [MASK]. activate this ability only during your turn.') if DO_PRE_TRAINING else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deck recommendations\n",
    "\n",
    "the dataset here is different: for each commander card you care about, text a is the commander card and text b is every possible other card in history (lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commanders = ['merieke ri berit',\n",
    "              'wort, boggart auntie',\n",
    "              \"kykar, wind's fury\",\n",
    "              'purphoros, bronze-blooded',\n",
    "              'marchesa, the black rose',\n",
    "              \"trostani, selesnya's voice\",\n",
    "              'mizzix of the izmagnus',\n",
    "              'oona, queen of the fae',\n",
    "              'zada, hedron grinder',\n",
    "              'breya, etherium shaper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commander_file_name(c):\n",
    "    f_out = (name_a\n",
    "                 .replace(\"'\", '')\n",
    "                 .replace(',', '')\n",
    "                 .replace(' ', '-'))\n",
    "    return f'{f_out}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DECK_RECOMMENDATION_INPUTS:\n",
    "    cards = get_cards()\n",
    "    \n",
    "    for name_a in commanders:\n",
    "        text_a = cards.loc[name_a].mytext\n",
    "        \n",
    "        df = (cards\n",
    "              [cards.index != name_a]\n",
    "              .copy()\n",
    "              .reset_index()\n",
    "              [['name', 'mytext']]\n",
    "              .rename(columns={'name': 'name_b',\n",
    "                               'mytest': 'text_b'}))\n",
    "        df.loc[:, 'name_a'] = name_a\n",
    "        df.loc[:, 'text_a'] = text_a\n",
    "        \n",
    "        f_out = commander_file_name(name_a)\n",
    "        print(f_out)\n",
    "        df.to_csv(f_out, index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_DECK_RECOMMENDATIONS:\n",
    "    EVAL_BATCH = 186\n",
    "    \n",
    "    # loading the trained model\n",
    "    config = BertConfig.from_pretrained(MODEL_NAME)\n",
    "    model = BertForNextSentencePrediction.from_pretrained(MODEL_NAME, config=config)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./ignore',\n",
    "        per_device_eval_batch_size=EVAL_BATCH\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(model=model, args=training_args, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_DECK_RECOMMENDATIONS:\n",
    "    tokenizer_map_func = build_tokenizer_map_func(tokenizer, max_length=MAX_SEQ_LENGTH)\n",
    "    \n",
    "    ds_to_check = (datasets.load_dataset('csv',\n",
    "                                         data_files={k: commander_file_name(k)\n",
    "                                                     for k in deck_names},\n",
    "                                         quoting=csv.QUOTE_ALL)\n",
    "                   .map(tokenizer_map_func, batched=True))\n",
    "\n",
    "ds_to_check if DO_DECK_RECOMMENDATIONS else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "if DO_DECK_RECOMMENDATIONS:\n",
    "    for deck_name in deck_names:\n",
    "        print(f\"deck_name = {deck_name}\")\n",
    "        p = trainer.predict(ds_to_check[deck_name])\n",
    "        print(f\"p.predictions.shape = {p.predictions.shape}\")\n",
    "\n",
    "        probs = softmax(p.predictions, axis=1)\n",
    "\n",
    "        z = pd.DataFrame({'p0': probs[:, 0],\n",
    "                          'p1': probs[:, 1],\n",
    "                          'y_pred': probs.argmax(axis=1),\n",
    "                          'name_b': ds_to_check[deck_name]['name_b'],\n",
    "                          'text_b': ds_to_check[deck_name]['text_b']})\n",
    "        z.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        recs = (z\n",
    "                .groupby(['name_b', 'text_b'])\n",
    "                .p0\n",
    "                .median()\n",
    "                .sort_values(ascending=False)\n",
    "                .reset_index())\n",
    "\n",
    "        recs.to_parquet(f\"{deck_name}.mlm-v2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
